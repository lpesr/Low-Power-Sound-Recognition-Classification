from os import listdir
from os.path import isfile, join
import numpy as np
from sklearn.svm import SVC
from sklearn.model_selection import RepeatedKFold
from sklearn.neural_network import MLPClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.mixture import GaussianMixture
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import f1_score
import pandas as pd
import os
import pickle
import sys
import time
from itertools import combinations

dirname = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))

sys.path.append(os.path.join(dirname, 'Src/FeatureExtractor'))
import DataPrep as dp

#Define all of the classifiers to test
classifiers = [
    SVC(kernel="rbf"),
    GaussianNB(),
    MLPClassifier(max_iter=1000),
]
names = [
    "RBF SVM",
    "Naive Bayes",
    "Neural Net",
]

def run_evaluation(augmentations, outputFile):
    output = open(outputFile, "a")

    output.write("Augmented Data," + names[0] + "," + names[1] + "," + names[2] + "\n")

    (originalX, originalY) = dp.prepare_input_data(os.path.join(dirname, "Data/Speech-Commands"), ["yes", "no", "on", "off"], 0.05, 0.75, 4, augmentation=(0,0,0))

    for augmentation in augmentations:
        test_augmented_dataset(augmentation, output, originalX, originalY)
    output.close()
            
def test_augmented_dataset(augmentation, outputFile, originalX, originalY):
    (augX, augY) = dp.prepare_input_data(os.path.join(dirname, "Data/Speech-Commands"), ["yes", "no", "on", "off"], 0.05, 0.75, 4, augmentation=augmentation) #4000)#, "jackhammer", "siren", "dog_bark"], 1500) #"glass_breaking", "siren", "hand_saw", "vacuum_cleaner", "crackling_fire"

    originalX = np.array(originalX)
    originalY = np.array(originalY)
    augX = np.array(augX)
    augY = np.array(augY)

    numKFoldSplits = 10
    numKFoldRep = 2

    #Create a results matrix
    i, j = numKFoldSplits * numKFoldRep, len(classifiers)
    results = [[0 for x in range(i)] for y in range(j)] 

    #Iterate over all of the classifiers
    for j in range(len(classifiers)):
        i = 0

        #K cross validate the data (there will be an equal number of both classes to train on)
        #This is because the data was split and then combined earlier
        kf = RepeatedKFold(n_splits=numKFoldSplits, n_repeats=numKFoldRep)
        for train, test in kf.split(augX):
            X_train, X_test = augX[train], originalX[test]
            y_train, y_test = augY[train], originalY[test]

            #Fit the classifier and label the testing split
            clf = classifiers[j].fit(X_train, y_train)

            preditctions = clf.predict(X_test)

            #Caculate the F1 score and store it
            results[j][i] = format(f1_score(y_test, preditctions, average='macro'), ".3f")

            i += 1

    outputFile.write(str(augmentation).replace(",", "|") + "," + format(sum(map(float, results[0][:])) / len(results[0]), ".3f") + "," + format(sum(map(float, results[1][:])) / len(results[1]), ".3f") + "," + format(sum(map(float, results[2][:])) / len(results[2]), ".3f") + "\n")
    outputFile.flush()

dirname = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))

augmentations = [(20, 0, 0), (10, 0, 0), (0, 20, 0), (0, 10, 0), (0, 0, 30), (0, 0, 60), (20, 20, 0), (20, 10, 0), (10, 20, 0), (10, 10, 0), (20, 20, 30), (20, 10, 30), (20, 20, 60), (20, 10, 60), (10, 20, 30), (10, 10, 30), (10, 20, 60), (10, 10, 60), (0, 20, 30), (0, 10, 30), (0, 20, 60), (0, 10, 80)]

run_evaluation(augmentations, "U:/GDP/ML Testing/Low-Power-Sound-Recognition-Classification/Output/augmentationOutputSpeechCommandsContinued.csv")